{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import argparse\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() # load environment variables from .env (add to .gitignore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(pdf_file: str) -> List[Dict[str, str]]:\n",
    "\n",
    "    endpoint = os.environ[\"DOCUMENT_ENDPOINT\"]\n",
    "    key = os.environ[\"DOCUMENT_KEY\"]\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "      endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "\n",
    "    if pdf_file.startswith(\"http\"):\n",
    "      poller = document_analysis_client.begin_analyze_document_from_url(\n",
    "          \"prebuilt-layout\", pdf_file)\n",
    "    else:\n",
    "      with open(pdf_file, \"rb\") as f:\n",
    "        poller = document_analysis_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\", document=f)\n",
    "\n",
    "    result = poller.result()\n",
    "    # Returns a dict representation of AnalyzeResult.\n",
    "    result_dict = result.to_dict()\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = parse_pdf(\"pdfs/MFC_QPR_2023_Q4_EN.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result dict keys():\n",
      " dict_keys(['api_version', 'model_id', 'content', 'languages', 'pages', 'paragraphs', 'tables', 'key_value_pairs', 'styles', 'documents'])\n",
      "\n",
      "Result dict.documents keys():\n",
      " dict_keys(['page_number', 'angle', 'width', 'height', 'unit', 'lines', 'words', 'selection_marks', 'spans', 'barcodes', 'formulas'])\n",
      "\n",
      "Result dict.pages keys():\n",
      " dict_keys(['page_number', 'angle', 'width', 'height', 'unit', 'lines', 'words', 'selection_marks', 'spans', 'barcodes', 'formulas'])\n",
      "\n",
      "Result dict.paragraphs keys():\n",
      " dict_keys(['role', 'content', 'bounding_regions', 'spans'])\n",
      "\n",
      "Result dict.tables keys()\n",
      ": dict_keys(['row_count', 'column_count', 'cells', 'bounding_regions', 'spans'])\n"
     ]
    }
   ],
   "source": [
    "print('Result dict keys():\\n', result_dict.keys())\n",
    "print('\\nResult dict.documents keys():\\n', result_dict.get('pages')[0].keys())\n",
    "print('\\nResult dict.pages keys():\\n', result_dict.get('pages')[0].keys())\n",
    "print('\\nResult dict.paragraphs keys():\\n', result_dict.get('paragraphs')[0].keys())\n",
    "print('\\nResult dict.tables keys()\\n:', result_dict.get('tables')[0].keys())\n",
    "# print('Result dict.tables keys():', result_dict.get('tables')[0]['cells'][20]['kind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict.get('pages')\n",
    "# for i, dict in enumerate(result_dict.get('pages')):\n",
    "#     print('Page number:', dict.get('page_number'), '\\n')\n",
    "#     for j, line in enumerate(dict.get('lines')):\n",
    "#         print('Line:', j, line.get('content'))\n",
    "\n",
    "# for paragraph in result_dict.get('paragraphs'):\n",
    "#     # print(paragraph)\n",
    "#     print(\"\\nParagraph:\\n\", paragraph.get('content'))\n",
    "#     print(\"Bounding regions:\\n\", paragraph.get('bounding_regions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_text_and_tables(result_dict):\n",
    "\n",
    "    page_contents = {}\n",
    "    # tables = []\n",
    "    # paragraphs = []\n",
    "\n",
    "    for i, paragraph in enumerate(result_dict.get('paragraphs')):\n",
    "        # print(paragraph.get('bounding_regions')[0].get('page_number'))\n",
    "        # print(page_contents.keys())\n",
    "        if paragraph.get('bounding_regions')[0].get('page_number') in page_contents.keys():\n",
    "            # print(paragraph.get('bounding_regions')[0].get('page_number'))\n",
    "            # print(i, page_contents[i])\n",
    "            page_contents[paragraph.get('bounding_regions')[0].get('page_number')].get('text').append(paragraph.get('content'))\n",
    "        else:\n",
    "            page_contents[paragraph.get('bounding_regions')[0].get('page_number')] = \\\n",
    "                {'tables': [], 'text': [paragraph.get('content')]}\n",
    "            # print(paragraph.get('bounding_regions')[0].get('page_number'))\n",
    "            # print(page_contents.keys())\n",
    "\n",
    "    for idx, atable in enumerate(result_dict[\"tables\"]):\n",
    "        # print(idx)\n",
    "        # if idx == -1:\n",
    "        #   continue\n",
    "        row_count = atable[\"row_count\"]\n",
    "        column_count = atable[\"column_count\"]\n",
    "        arr = np.empty((row_count, column_count), dtype=object)\n",
    "        arr[-1][:] = \"\"\n",
    "        for aval in atable[\"cells\"]:\n",
    "        # Handles complex headers\n",
    "            if aval[\"kind\"] == \"columnHeader\":\n",
    "                arr[-1][aval[\"column_index\"]:aval[\"column_index\"] +\n",
    "                    aval[\"column_span\"]] += str(aval[\"content\"])\n",
    "            else:\n",
    "                arr[aval[\"row_index\"]][aval[\"column_index\"]] = aval[\"content\"]\n",
    "\n",
    "        df = pd.DataFrame(arr)\n",
    "        # print(df)\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.drop(df.index[0:2])\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        df.dropna(inplace=True)\n",
    "        page_contents[atable.get('bounding_regions')[0].get('page_number')].get('tables').append(df)\n",
    "        # tables.append(df)\n",
    "\n",
    "    return page_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = page_text_and_tables(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for page_no, item in page_contents.items():\n",
    "#     print('Page number:', page_no)\n",
    "#     print('Number of tables:', len(item['tables']))\n",
    "#     print('Lenght of text:', len(item['text']))\n",
    "#     print('Text:', item['text'])\n",
    "#     if item['tables']:\n",
    "#         for i, table in enumerate(item['tables']):\n",
    "#             print('Table:', i+1, 'in page', page_no, '\\n', table, '\\n')\n",
    "#     print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
